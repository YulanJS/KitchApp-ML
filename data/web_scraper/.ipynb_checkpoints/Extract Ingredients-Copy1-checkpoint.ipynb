{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../recipebox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "datasets = glob(data_root + \"/recipes*.json\")\n",
    "datasets = datasets[1], datasets[0], datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppers = (\",\", \";\") # stop reading the string here\n",
    "\n",
    "measure_words = (\n",
    "    # from https://en.wikipedia.org/wiki/Cooking_weights_and_measures#United_States_measures\n",
    "    \"scant\",\n",
    "    \"drop\",\n",
    "    \"smidgen\",\n",
    "    \"pinch\",\n",
    "    \"dash\",\n",
    "    \"head\",\n",
    "    \"piece\",\n",
    "    \"splash\",\n",
    "    \"squeeze\",\n",
    "    # from # from https://en.wikibooks.org/wiki/Cookbook:Units_of_measurement\n",
    "    # fluid\n",
    "    \"teaspoon\",\"t\", \"tsp\",\n",
    "    \"tablespoon\", \"T\", \"tbl\", \"tbs\", \"tbsp\", \n",
    "    \"fluid ounce\", \"fl oz\",\n",
    "    \"gill\",\n",
    "    \"cup\", \"c\",\n",
    "    \"pint\", \"p\", \"pt\", \"fl pt\",\n",
    "    \"quart\", \"q\", \"qt\", \"fl qt\",\n",
    "    \"gallon\", \"g\", \"gal\",\n",
    "    \"ml\", \"milliliter\", \"millilitre\", \"cc\",\n",
    "    \"l\", \"liter\", \"litre\",\n",
    "    \"dl\", \"deciliter\", \"decilitre\",\n",
    "    \"can\",\n",
    "    \"bottle\",\n",
    "    # weight\n",
    "    \"pound\", \"lb\" \"#\",\n",
    "    \"ounce\", \"oz\",\n",
    "    \"mg\", \"milligram\", \"milligramme\",\n",
    "    \"g\", \"gram\", \"gramme\",\n",
    "    \"kg\", \"kilogram\", \"kilogramme\",\n",
    "    # length\n",
    "    \"mm\", \"millimeter\", \"millimetre\",\n",
    "    \"cm\", \"centimeter\", \"centimetre\",\n",
    "    \"m\", \"meter\", \"metre\",\n",
    "    \"inch\", \"in\",\n",
    "    # size\n",
    "    \"large\",\n",
    "    \"medium\",\n",
    "    \"small\",\n",
    "    \"about\",\n",
    "    # quantifiers\n",
    "    \"half\",\n",
    "    \"single\",\n",
    "    \"couple\",\n",
    "    \"dozen\",\n",
    "    \"many\",\n",
    "    \"each\",\n",
    "    \"some\",\n",
    "    \"every\",\n",
    "    \"pair\",\n",
    "    \"additional\",\n",
    "    \"approx\",\n",
    "    \"more\",\n",
    "    \"less\",\n",
    "    # misc\n",
    "    \"bag\",\n",
    "    \"box\",\n",
    "    \"bunch\",\n",
    "    \"handful\",\n",
    "    \"slice\",\n",
    "    \"end\",\n",
    "    \"accompaniment\"\n",
    ")\n",
    "\n",
    "\n",
    "adjective_endings = (\"ly\",) # remove any word that ends with this\n",
    "verb_endings = (\"ed\",) # e.g. packed, melted, chopped, chilled, divided, trimmed, grated\n",
    "endings = verb_endings + adjective_endings\n",
    "endings\n",
    "\n",
    "to_remove = (\n",
    "    \"advertisement\", \n",
    "    \"of\", \"a\", \"the\", \"an\",\n",
    "    \"to\", \"about\", \"from\", \"at\", \"by\", \"as\", \"above\", \"below\", \"abs\",\n",
    "    \"recipe\",\n",
    "    \"favorite\", \"choice\", \n",
    "    \"fat\", \"free\", \"taste\", \"garnish\",\n",
    "    \"baby\", \"plump\", \"pure\", \"simple\", \"fresh\", \"torn\", \"good\", \"quality\", \"brand\", \"new\", \"dusting\",\n",
    "    \"very\",\n",
    "    \n",
    ")\n",
    "cardinal_numbers = (\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\", \"twenty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def lower(string):\n",
    "    return string.lower()\n",
    "\n",
    "def remove_after_stopper(string):\n",
    "    # remove after any comma, colon, or period\n",
    "    return re.sub(r\"[,;\\.].*\", \"\", string)\n",
    "\n",
    "def remove_between_paren(string):\n",
    "    # \\( and \\) for parentheses characters\n",
    "    return re.sub(r\"\\(.*\\)\", \"\", string)\n",
    "\n",
    "def remove_measure_words(string):\n",
    "    for m in measure_words:\n",
    "        # greater than 1, don't want to apply to single letters. E.g. c for cups\n",
    "        if len(m) > 1:\n",
    "            # \\b word boundary, %s the measure word, [a-zA-Z]* any number of following letters, \\b word boundary\n",
    "            string = re.sub(r\"\\b%s[a-zA-z]*\\b\" %m, \"\", string)\n",
    "        else:\n",
    "            string = re.sub(r\"\\b%s\\b\" %m, \"\", string)\n",
    "    return string\n",
    "\n",
    "def remove_nonalpha(string):\n",
    "    # first replace dashes with spaces\n",
    "    string = string.replace(\"-\", \" \")\n",
    "    # ^ not, [a-zA-z] letter, \\s space\n",
    "    return re.sub(r\"[^a-zA-Z\\s]\", \"\", string)\n",
    "\n",
    "def remove_endings(string):\n",
    "    for end in endings:\n",
    "        string = re.sub(r\"\\b[\\w]+%s\\b\" %end, \"\", string)\n",
    "    return string\n",
    "\n",
    "def remove_less_than(num):\n",
    "    def remove_less_than_from_str(string):\n",
    "        # remove words with less than num letters\n",
    "        return re.sub(r\"\\b[\\w]{%s}\\b\" % \",\".join(str(i) for i in range(1,num+1)), \"\", string)\n",
    "    return remove_less_than_from_str\n",
    "\n",
    "def remove_dumb_words(string):\n",
    "    for word in to_remove + cardinal_numbers:\n",
    "        string = re.sub(r\"\\b%s\\b\" % word, \"\", string)\n",
    "    return string\n",
    "\n",
    "def remove_available_at(string):\n",
    "    \"\"\" remove 'available at *** markets' \"\"\"\n",
    "    return re.sub(r\"available at.*markets\", \"\", string)\n",
    "\n",
    "def remove_extra_spaces(string):\n",
    "    return re.sub(r\"\\s+\", \" \", string)\n",
    "\n",
    "def strip(string):\n",
    "    return string.strip()\n",
    "\n",
    "import functools\n",
    "def compose(*functions):\n",
    "    # we have to reverse to get in the desired order\n",
    "    functions = reversed(functions)\n",
    "    return functools.reduce(lambda f, g: lambda x: f(g(x)), functions, lambda x: x)\n",
    "\n",
    "functions = (\n",
    "    lower,\n",
    "    remove_after_stopper, \n",
    "    remove_between_paren, \n",
    "    remove_measure_words, \n",
    "    remove_nonalpha, \n",
    "    remove_endings,\n",
    "    remove_less_than(2),\n",
    "    remove_dumb_words,\n",
    "    remove_available_at,\n",
    "    remove_extra_spaces, \n",
    "    strip\n",
    ")\n",
    "extract_ingredient = compose(*functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomatoes ', ' potatos']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"and|or\", \"tomatoes and potatos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2713b20caf8467081bc23cd31a64a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dataset', max=3, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ../recipebox/recipes_raw_nosource_fn.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "recipes: 100%|██████████| 60039/60039 [01:51<00:00, 539.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ../recipebox/recipes_raw_nosource_epi.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "recipes: 100%|██████████| 25323/25323 [00:42<00:00, 595.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ../recipebox/recipes_raw_nosource_ar.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "recipes: 100%|██████████| 39802/39802 [01:05<00:00, 605.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "ingredients = defaultdict(int)\n",
    "ingredients_to_recipe_ids = defaultdict(set)\n",
    "\n",
    "for ds in tqdm(datasets, desc=\"Dataset\"):\n",
    "    print(\"Loading dataset\", ds)\n",
    "    df = pd.read_json(ds)\n",
    "    all_ingredient_lists = df.loc[\"ingredients\"]\n",
    "    for i in trange(len(all_ingredient_lists), desc=\"recipes\"):\n",
    "        try:\n",
    "            recipe_id = all_ingredient_lists.index[i]\n",
    "            ingredient_list = all_ingredient_lists[i]\n",
    "\n",
    "            if type(ingredient_list) != list:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            for ingredient_string in ingredient_list:\n",
    "                # SPLIT THE INGREDIENT STRING ON AND & OR & PLUS\n",
    "                parts = re.split(r\"\\band\\b|\\bor\\b|\\bplus\\b\", ingredient_string)\n",
    "                if len(parts) > 1:\n",
    "                    ingredient_list += parts[1:] # add other parts later to continue iteration\n",
    "                    ingredient_string = parts[0]\n",
    "                \n",
    "                ingredient = extract_ingredient(ingredient_string)\n",
    "                if ingredient: # ignore empty string\n",
    "                    ingredients[ingredient] += 1\n",
    "                    ingredients_to_recipe_ids[ingredient].add(recipe_id)        \n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Warning! failed on {str(ingredient_list)}\")\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f83595bef0d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mingredients_to_recipe_ids_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredients_to_recipe_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/keras-tf/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"only recognize index or columns for orient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/keras-tf/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    409\u001b[0m             )\n\u001b[1;32m    410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/keras-tf/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         ]\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/keras-tf/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/keras-tf/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "ingredients_to_recipe_ids_df = pd.DataFrame.from_dict(ingredients_to_recipe_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order(my_dict):\n",
    "    return sorted(my_dict.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order(ingredients)[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, counts = zip(*order(ingredients))\n",
    "sorted(names[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def combine_similar(my_dict, ratio=0.65, combine_reverse=True):\n",
    "    \"\"\"\n",
    "    combines similar keys in the dictionary\n",
    "    \n",
    "    assumes the relevant similar parts are at the end of the key\n",
    "    \"\"\"\n",
    "    new_dict = defaultdict(int)\n",
    "    \n",
    "    # we sort by the tail ends. puts tail ends next to each other. better similarity this way.\n",
    "    # e.g. \"awesome lemon zest\" and \"weird lemon zest\" are typically far apart.\n",
    "    # sorting from the ends puts them next to each other\n",
    "    sorted_keys = sorted(my_dict, key=lambda x: x[::-1].replace(\" \", \"Ω\") if combine_reverse else x.replace(\" \", \"Ω\")) \n",
    "    prev = \"\"\n",
    "    for k in sorted_keys:\n",
    "        if similarity(prev, k) > ratio:\n",
    "            new_dict[prev] = my_dict[prev] + my_dict[k]\n",
    "        else:\n",
    "            new_dict[k] = my_dict[k]\n",
    "            prev = k\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ingredients = combine_similar(ingredients)\n",
    "len(combined_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order(combined_ingredients)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, counts = zip(*order(combined_ingredients))\n",
    "sorted(names[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE SIMILAR AGAIN, but this time with higher ratio 0.9 to get rid of plurals\n",
    "refiltered = order(combine_similar(dict(order(combined_ingredients)[:500]), ratio=0.9, combine_reverse=False))\n",
    "refiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, c = zip(*refiltered)\n",
    "n = list(n)\n",
    "n.remove(\"more\")\n",
    "n.remove(\"more for\")\n",
    "n.remove(\"more for dusting\")\n",
    "sorted(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r\"\\band\\b|\\bor\\b|\\bplus\\b\", \"oregano and oranges andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Ω\" < \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
